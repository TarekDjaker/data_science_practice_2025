{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n"
      ],
      "metadata": {
        "id": "IM27-5wJq0vJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datas_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv'\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "download_file(train_datas_url, 'module4_exercise_train.zip')\n",
        "download_file(test_data_url, 'Neighborhood_Market_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQINSSD-q3Jl",
        "outputId": "9faf5279-1c59-40ca-8e9e-0a24e03d6b39"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded module4_exercise_train.zip from https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip\n",
            "Downloaded Neighborhood_Market_data.csv from https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with zipfile.ZipFile(\"module4_exercise_train.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"train_data\")\n",
        "\n",
        "\n",
        "df_city = pd.read_csv(\"train_data/CityMart_data.csv\")\n",
        "df_green = pd.read_csv(\"train_data/Greenfield_Grocers_data.csv\")\n",
        "df_outlet = pd.read_excel(\"train_data/SuperSaver_Outlet_data.xlsx\")\n",
        "df_bazaar = pd.read_json(\"train_data/HighStreet_Bazaar_data.json\")\n",
        "\n",
        "df_train = pd.concat([df_city, df_green, df_outlet, df_bazaar], ignore_index=True)\n",
        "df_test = pd.read_csv(\"Neighborhood_Market_data.csv\")\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQS9BMDnq6iI",
        "outputId": "1087ef5d-246b-4f82-f9cd-6bf8af250bfe"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1594, 12)\n",
            "Test shape: (409, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "url_auth = \"https://www.raphaelcousin.com/api/exercise/auth\"\n",
        "r = requests.get(url_auth)\n",
        "r.raise_for_status()\n",
        "auth_data = r.json()\n",
        "\n",
        "password = auth_data[\"data\"][\"password\"]\n",
        "print(\"üîë Password r√©cup√©r√© :\", password)\n",
        "\n",
        "\n",
        "url_prices = f\"https://www.raphaelcousin.com/api/exercise/{password}/prices\"\n",
        "r = requests.get(url_prices)\n",
        "r.raise_for_status()\n",
        "prices_data = r.json()\n",
        "\n",
        "\n",
        "data_dict = prices_data[\"data\"]\n",
        "df_prices = pd.DataFrame(list(data_dict.items()), columns=[\"item_code\", \"unit_cost\"])\n",
        "\n",
        "print(\" Aper√ßu de df_prices :\")\n",
        "print(df_prices.head())\n",
        "\n",
        "\n",
        "df_train = df_train.merge(df_prices, on=\"item_code\", how=\"left\")\n",
        "df_test = df_test.merge(df_prices, on=\"item_code\", how=\"left\")\n",
        "\n",
        "print(\" Colonne unit_cost ajout√©e :\", df_prices.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkePxfqavFoC",
        "outputId": "40340552-8685-4ad7-98a7-66cd01abe61f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Password r√©cup√©r√© : RcUZjhdsYLRzwi4\n",
            " Aper√ßu de df_prices :\n",
            "  item_code  unit_cost\n",
            "0     P0001      22.14\n",
            "1     P0002      26.91\n",
            "2     P0003      16.90\n",
            "3     P0004       7.04\n",
            "4     P0005      20.84\n",
            " Colonne unit_cost ajout√©e : (2000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium chromedriver-autoinstaller\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWIuEpmwimc",
        "outputId": "2845f16b-994a-4638-e3e6-84f8fd7cd6bb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.12/dist-packages (0.6.4)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "url = \"https://www.raphaelcousin.com/module4/scrapable-data\"\n",
        "driver.get(url)\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "html = driver.page_source\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "tables = soup.find_all(\"table\")\n",
        "print(\" Nombre de tables trouv√©es :\", len(tables))\n",
        "\n",
        "\n",
        "rows = []\n",
        "for row in exercise_table.find(\"tbody\").find_all(\"tr\"):\n",
        "    cols = [col.text.strip() for col in row.find_all(\"td\")]\n",
        "    rows.append(cols)\n",
        "\n",
        "\n",
        "df_exercise = pd.DataFrame(\n",
        "    rows,\n",
        "    columns=[\"item_code\", \"customer_score\", \"total_reviews\", \"extra_col\"]\n",
        ")\n",
        "\n",
        "\n",
        "df_exercise = df_exercise[[\"item_code\", \"customer_score\", \"total_reviews\"]]\n",
        "\n",
        "\n",
        "df_exercise[\"customer_score\"] = pd.to_numeric(df_exercise[\"customer_score\"], errors=\"coerce\")\n",
        "df_exercise[\"total_reviews\"] = pd.to_numeric(df_exercise[\"total_reviews\"], errors=\"coerce\")\n",
        "\n",
        "print(\" Aper√ßu du scraping corrig√© :\")\n",
        "print(df_exercise.head())\n",
        "\n",
        "\n",
        "df_train = df_train.merge(df_exercise, on=\"item_code\", how=\"left\")\n",
        "df_test = df_test.merge(df_exercise, on=\"item_code\", how=\"left\")\n",
        "\n",
        "print(\" Colonnes customer_score et total_reviews ajout√©es :\", df_train.shape, df_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Bji5svwmc0",
        "outputId": "4e5571c7-22b6-482a-f953-bea62dd29491"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nombre de tables trouv√©es : 2\n",
            " Aper√ßu du scraping corrig√© :\n",
            "  item_code  customer_score  total_reviews\n",
            "0     P0001               2            972\n",
            "1     P0002               3            260\n",
            "2     P0003               2            285\n",
            "3     P0004               5            512\n",
            "4     P0005               3             85\n",
            " Colonnes customer_score et total_reviews ajout√©es : (1594, 15) (409, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = df_train.dropna(subset=[\"quantity_sold\"])\n",
        "print(\" Apr√®s nettoyage, taille train :\", df_train.shape)\n",
        "\n",
        "\n",
        "if \"unit_cost_x\" in df_train.columns and \"unit_cost_y\" in df_train.columns:\n",
        "    df_train[\"unit_cost\"] = df_train[[\"unit_cost_x\", \"unit_cost_y\"]].mean(axis=1)\n",
        "    df_train = df_train.drop(columns=[\"unit_cost_x\", \"unit_cost_y\"])\n",
        "\n",
        "if \"unit_cost_x\" in df_test.columns and \"unit_cost_y\" in df_test.columns:\n",
        "    df_test[\"unit_cost\"] = df_test[[\"unit_cost_x\", \"unit_cost_y\"]].mean(axis=1)\n",
        "    df_test = df_test.drop(columns=[\"unit_cost_x\", \"unit_cost_y\"])\n",
        "\n",
        "\n",
        "cols_to_keep = [\n",
        "    \"mass\", \"dimension_length\", \"dimension_width\", \"dimension_height\",\n",
        "    \"days_since_last_purchase\", \"package_volume\", \"stock_age\",\n",
        "    \"unit_cost\", \"customer_score\", \"total_reviews\"\n",
        "]\n",
        "\n",
        "\n",
        "common_cols = [c for c in cols_to_keep if c in df_test.columns and c in df_train.columns]\n",
        "\n",
        "print(\"Colonnes finales train :\", df_train[common_cols + [\"quantity_sold\"]].columns.tolist())\n",
        "print(\"Colonnes finales test :\", df_test[common_cols].columns.tolist())\n",
        "\n",
        "X_train = df_train[common_cols + [\"quantity_sold\"]]\n",
        "X_test = df_test[common_cols]\n",
        "\n",
        "\n",
        "mae, preds = get_simple_baseline(\n",
        "    data=X_train,\n",
        "    target_col=\"quantity_sold\",\n",
        "    k_fold=5,\n",
        "    scaler=\"standard\",\n",
        "    X_data_test=X_test\n",
        ")\n",
        "\n",
        "print(f\" MAE obtenu : {mae:.2f}\")\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"item_code\": df_test[\"item_code\"].values,   # ‚úÖ on prend la vraie colonne item_code\n",
        "    \"quantity_sold\": np.maximum(0, preds.astype(int))\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"‚úÖ submission.csv g√©n√©r√© avec\", len(submission), \"lignes\")\n",
        "print(submission.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSggr9CT6LgO",
        "outputId": "afff51ea-954c-4b99-fed3-722e9d5d0587"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Apr√®s nettoyage, taille train : (1190, 15)\n",
            "Colonnes finales train : ['mass', 'dimension_length', 'dimension_width', 'dimension_height', 'days_since_last_purchase', 'package_volume', 'stock_age', 'unit_cost', 'customer_score', 'total_reviews', 'quantity_sold']\n",
            "Colonnes finales test : ['mass', 'dimension_length', 'dimension_width', 'dimension_height', 'days_since_last_purchase', 'package_volume', 'stock_age', 'unit_cost', 'customer_score', 'total_reviews']\n",
            " MAE moyen (cross-val): 20.704061924114214\n",
            " MAE obtenu : 20.70\n",
            "‚úÖ submission.csv g√©n√©r√© avec 409 lignes\n",
            "  item_code  quantity_sold\n",
            "0     P0002            196\n",
            "1     P0004            278\n",
            "2     P0005            192\n",
            "3     P0010            260\n",
            "4     P0013            271\n"
          ]
        }
      ]
    }
  ]
}