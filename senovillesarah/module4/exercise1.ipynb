{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n"
      ],
      "metadata": {
        "id": "IM27-5wJq0vJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datas_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv'\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "download_file(train_datas_url, 'module4_exercise_train.zip')\n",
        "download_file(test_data_url, 'Neighborhood_Market_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQINSSD-q3Jl",
        "outputId": "4f697162-53f3-4bfa-8185-8d3edb1178b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded module4_exercise_train.zip from https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip\n",
            "Downloaded Neighborhood_Market_data.csv from https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with zipfile.ZipFile(\"module4_exercise_train.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"train_data\")\n",
        "\n",
        "\n",
        "df_city = pd.read_csv(\"train_data/CityMart_data.csv\")\n",
        "df_green = pd.read_csv(\"train_data/Greenfield_Grocers_data.csv\")\n",
        "df_outlet = pd.read_excel(\"train_data/SuperSaver_Outlet_data.xlsx\")\n",
        "df_bazaar = pd.read_json(\"train_data/HighStreet_Bazaar_data.json\")\n",
        "\n",
        "df_train = pd.concat([df_city, df_green, df_outlet, df_bazaar], ignore_index=True)\n",
        "df_test = pd.read_csv(\"Neighborhood_Market_data.csv\")\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQS9BMDnq6iI",
        "outputId": "b1d6c281-0659-42f1-8190-6fa0c524e45b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1594, 12)\n",
            "Test shape: (409, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "url_auth = \"https://www.raphaelcousin.com/api/exercise/auth\"\n",
        "r = requests.get(url_auth)\n",
        "r.raise_for_status()\n",
        "auth_data = r.json()\n",
        "\n",
        "password = auth_data[\"data\"][\"password\"]\n",
        "print(\"üîë Password r√©cup√©r√© :\", password)\n",
        "\n",
        "\n",
        "url_prices = f\"https://www.raphaelcousin.com/api/exercise/{password}/prices\"\n",
        "r = requests.get(url_prices)\n",
        "r.raise_for_status()\n",
        "prices_data = r.json()\n",
        "\n",
        "\n",
        "data_dict = prices_data[\"data\"]\n",
        "df_prices = pd.DataFrame(list(data_dict.items()), columns=[\"item_code\", \"unit_cost\"])\n",
        "\n",
        "print(\" Aper√ßu de df_prices :\")\n",
        "print(df_prices.head())\n",
        "\n",
        "\n",
        "df_train = df_train.merge(df_prices, on=\"item_code\", how=\"left\")\n",
        "df_test = df_test.merge(df_prices, on=\"item_code\", how=\"left\")\n",
        "\n",
        "print(\" Colonne unit_cost ajout√©e :\", df_prices.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkePxfqavFoC",
        "outputId": "e790c8b3-3027-4e98-f583-7f76e780c232"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Password r√©cup√©r√© : RcUZjhdsYLRzwi4\n",
            " Aper√ßu de df_prices :\n",
            "  item_code  unit_cost\n",
            "0     P0001      22.14\n",
            "1     P0002      26.91\n",
            "2     P0003      16.90\n",
            "3     P0004       7.04\n",
            "4     P0005      20.84\n",
            " Colonne unit_cost ajout√©e : (2000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium chromedriver-autoinstaller\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWIuEpmwimc",
        "outputId": "160ab8f2-9219-4254-bece-6483ad6b4937"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver-autoinstaller\n",
            "Successfully installed chromedriver-autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "url = \"https://www.raphaelcousin.com/module4/scrapable-data\"\n",
        "driver.get(url)\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "html = driver.page_source\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "tables = soup.find_all(\"table\")\n",
        "print(\" Nombre de tables trouv√©es :\", len(tables))\n",
        "\n",
        "\n",
        "rows = []\n",
        "for row in exercise_table.find(\"tbody\").find_all(\"tr\"):\n",
        "    cols = [col.text.strip() for col in row.find_all(\"td\")]\n",
        "    rows.append(cols)\n",
        "\n",
        "\n",
        "df_exercise = pd.DataFrame(\n",
        "    rows,\n",
        "    columns=[\"item_code\", \"customer_score\", \"total_reviews\", \"extra_col\"]\n",
        ")\n",
        "\n",
        "\n",
        "df_exercise = df_exercise[[\"item_code\", \"customer_score\", \"total_reviews\"]]\n",
        "\n",
        "\n",
        "df_exercise[\"customer_score\"] = pd.to_numeric(df_exercise[\"customer_score\"], errors=\"coerce\")\n",
        "df_exercise[\"total_reviews\"] = pd.to_numeric(df_exercise[\"total_reviews\"], errors=\"coerce\")\n",
        "\n",
        "print(\" Aper√ßu du scraping corrig√© :\")\n",
        "print(df_exercise.head())\n",
        "\n",
        "\n",
        "df_train = df_train.merge(df_exercise, on=\"item_code\", how=\"left\")\n",
        "df_test = df_test.merge(df_exercise, on=\"item_code\", how=\"left\")\n",
        "\n",
        "print(\" Colonnes customer_score et total_reviews ajout√©es :\", df_train.shape, df_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Bji5svwmc0",
        "outputId": "7104093a-2dd9-44c3-d965-f64ea7bdc91f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nombre de tables trouv√©es : 2\n",
            " Aper√ßu du scraping corrig√© :\n",
            "  item_code  customer_score  total_reviews\n",
            "0     P0001               2            972\n",
            "1     P0002               3            260\n",
            "2     P0003               2            285\n",
            "3     P0004               5            512\n",
            "4     P0005               3             85\n",
            " Colonnes customer_score et total_reviews ajout√©es : (1594, 15) (409, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_simple_baseline(data, target_col, k_fold=5, scaler='standard', X_data_test=None):\n",
        "    data = data.copy()\n",
        "\n",
        "\n",
        "    y = data[target_col]\n",
        "    X = data.drop(columns=[target_col])\n",
        "\n",
        "\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(-1)\n",
        "    if X_data_test is not None:\n",
        "        X_data_test = X_data_test.apply(pd.to_numeric, errors=\"coerce\").fillna(-1)\n",
        "\n",
        "\n",
        "    if scaler == 'standard':\n",
        "        sc = StandardScaler()\n",
        "        X = sc.fit_transform(X)\n",
        "        if X_data_test is not None:\n",
        "            X_data_test = sc.transform(X_data_test)\n",
        "\n",
        "\n",
        "    model = LinearRegression()\n",
        "    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        scores.append(mean_absolute_error(y_val, y_pred))\n",
        "\n",
        "    print(\" MAE moyen (cross-val):\", np.mean(scores))\n",
        "\n",
        "    if X_data_test is not None:\n",
        "        model.fit(X, y)\n",
        "        return np.mean(scores), model.predict(X_data_test)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "\n",
        "bad_cols = [c for c in df_train.columns if \"|\" in c or c.strip() == \"\"]\n",
        "print(\"Colonnes supprim√©es :\", bad_cols)\n",
        "\n",
        "df_train = df_train.drop(columns=bad_cols, errors=\"ignore\")\n",
        "df_test = df_test.drop(columns=bad_cols, errors=\"ignore\")\n",
        "\n",
        "\n",
        "cols_to_drop = [\"item_code\", \"store_name\", \"last_modified\", \"unit_cost_y\"]\n",
        "for col in cols_to_drop:\n",
        "    if col in df_train.columns:\n",
        "        df_train = df_train.drop(columns=[col])\n",
        "    if col in df_test.columns:\n",
        "        df_test = df_test.drop(columns=[col])\n",
        "\n",
        "\n",
        "df_train = df_train.dropna(subset=[\"quantity_sold\"])\n",
        "print(\"‚úÖ Apr√®s nettoyage, taille train :\", df_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "mae, preds = get_simple_baseline(\n",
        "    data=df_train,\n",
        "    target_col=\"quantity_sold\",\n",
        "    k_fold=5,\n",
        "    scaler=\"standard\",\n",
        "    X_data_test=df_test\n",
        ")\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"item_code\": df_test.index,\n",
        "    \"quantity_sold\": np.maximum(0, preds.astype(int))\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"‚úÖ submission.csv g√©n√©r√© avec\", len(submission), \"lignes\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT31-wviz4LY",
        "outputId": "93ef75e3-af11-498d-b7a3-165ba1cc261b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colonnes supprim√©es : ['||||||||||||']\n",
            "‚úÖ Apr√®s nettoyage, taille train : (1190, 11)\n",
            " MAE moyen (cross-val): 20.704061924114214\n",
            "‚úÖ submission.csv g√©n√©r√© avec 409 lignes\n",
            "   item_code  quantity_sold\n",
            "0          0            196\n",
            "1          1            278\n",
            "2          2            192\n",
            "3          3            260\n",
            "4          4            271\n"
          ]
        }
      ]
    }
  ]
}